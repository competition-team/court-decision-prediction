{"cells":[{"cell_type":"markdown","id":"4a92423c","metadata":{"id":"4a92423c"},"source":["# 1. Configurations"]},{"cell_type":"markdown","id":"23a3a9e9","metadata":{"id":"23a3a9e9"},"source":["## 1.1 Install Packages"]},{"cell_type":"code","source":["!pip install colab_ssh\n","\n","from colab_ssh import launch_ssh_cloudflared\n","launch_ssh_cloudflared(password='test')\n","\n","from google.colab import drive\n","drive.mount('/mnt')\n","\n","!ln -s /mnt/MyDrive/court-decision-prediction /root\n","%cd /root/court-decision-prediction"],"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":239},"id":"YWEudFlx2xZf","outputId":"e954b665-90ef-4297-88ef-0c5c66fabaf8"},"id":"YWEudFlx2xZf","execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: colab_ssh in /usr/local/lib/python3.10/dist-packages (0.3.27)\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["<style>\n","*{\n","\toutline:none;\n","}\n","code{\n","\tdisplay:inline-block;\n","\tpadding:5px 10px;\n","\tbackground: #444;\n","\tborder-radius: 4px;\n","\twhite-space: pre-wrap;\n","\tposition:relative;\n","\tcolor:white;\n","}\n",".copy-code-button{\n","\tfloat:right;\n","\tbackground:#333;\n","\tcolor:white;\n","\tborder: none;\n","\tmargin: 0 0 0 10px;\n","\tcursor: pointer;\n","}\n","p, li{\n","\tmax-width:700px;\n","}\n",".choices{\n","\tdisplay:flex;\n","\tflex: 1 0 auto;\n","}\n",".choice-section{\n","\tborder:solid 1px #555;\n","\tborder-radius: 4px;\n","\tmin-width:300px;\n","\tmargin: 10px 15px 0 0;\n","\tpadding: 0 15px 15px 15px ;\n","}\n",".button{\n","\tpadding: 10px 15px;\n","\tbackground:#333;\n","\tborder-radius: 4px;\n","\tborder:solid 1px #555;\n","\tcolor:white;\n","\tfont-weight:bold;\n","\tcursor:pointer;\n","}\n",".pill{\n","\tpadding:2px 4px;\n","\tborder-radius: 100px;\n","\tbackground-color:#e65858;\n","\tfont-size:12px;\n","\tfont-weight:bold;\n","\tmargin: 0 15px;\n","\tcolor:white;\n","}\n","</style>\n","<details class=\"choice-section\">\n","\t<summary style=\"cursor:pointer\">\n","\t\t<h3 style=\"display:inline-block;margin-top:15px\">⚙️ Client machine configuration<span class=\"pill\">Required</span></h3>\n","\t</summary>\n","\t<p>Don't worry, you only have to do this <b>once per client machine</b>.</p>\n","\t<ol>\n","\t\t<li>Download <a href=\"https://developers.cloudflare.com/argo-tunnel/getting-started/installation\">Cloudflared (Argo Tunnel)</a>, then copy the absolute path of the cloudflare binary</li>\n","\t\t<li>Now, you have to append the following to your SSH config file (usually under ~/.ssh/config), and make sure you replace the placeholder with the path you copied in Step 1:</li>\n","\t</ol>\n","\t<code>Host *.trycloudflare.com\n","\tHostName %h\n","\tUser root\n","\tPort 22\n","\tProxyCommand &ltPUT_THE_ABSOLUTE_CLOUDFLARE_PATH_HERE&gt access ssh --hostname %h\n","\t</code>\n","</details>\n","<div class=\"choices\">\n","\t<div class=\"choice-section\">\n","\t\t<h4>SSH Terminal</h4>\n","\t\t<p>To connect using your terminal, type this command:</p>\n","\t\t<code>ssh ericsson-gale-complications-facts.trycloudflare.com</code>\n","\t</div>\n","\t<div class=\"choice-section\">\n","\t\t<h4>VSCode Remote SSH</h4>\n","\t\t<p>You can also connect with VSCode Remote SSH (Ctrl+Shift+P and type \"Connect to Host...\"). Then, paste the following hostname in the opened command palette:</p>\n","\t\t<code>ericsson-gale-complications-facts.trycloudflare.com</code>\n","\t</div>\n","</div>\n","\n","<script>\n","// Copy any string\n","function fallbackCopyTextToClipboard(text) {\n","  var textArea = document.createElement(\"textarea\");\n","  textArea.value = text;\n","  \n","  // Avoid scrolling to bottom\n","  textArea.style.top = \"0\";\n","  textArea.style.left = \"0\";\n","  textArea.style.position = \"fixed\";\n","\n","  document.body.appendChild(textArea);\n","  textArea.focus();\n","  textArea.select();\n","\n","  try {\n","    var successful = document.execCommand('copy');\n","    var msg = successful ? 'successful' : 'unsuccessful';\n","    console.log('Fallback: Copying text command was ' + msg);\n","  } catch (err) {\n","    console.error('Fallback: Oops, unable to copy', err);\n","  }\n","\n","  document.body.removeChild(textArea);\n","}\n","\n","// Show the copy button with every code tag\n","document.querySelectorAll('code').forEach(function (codeBlock) {\n","\tconst codeToCopy= codeBlock.innerText;\n","\tvar pre = document.createElement('pre');\n","\tpre.innerText = codeToCopy;\n","    var button = document.createElement('button');\n","    button.className = 'copy-code-button';\n","    button.type = 'button';\n","    button.innerText = 'Copy';\n","\tbutton.onclick = function(){\n","\t\tfallbackCopyTextToClipboard(codeToCopy);\n","\t\tbutton.innerText = 'Copied'\n","\t\tsetTimeout(()=>{\n","\t\t\tbutton.innerText = 'Copy'\n","\t\t},2000)\n","\t}\n","\tcodeBlock.children = pre;\n","\tcodeBlock.prepend(button)\n","});\n","</script>\n"]},"metadata":{}}]},{"cell_type":"code","execution_count":null,"id":"11351932","metadata":{"id":"11351932"},"outputs":[],"source":["!pip install transformers==4.30.2 loralib==0.1.1 sentencepiece==0.1.99 livelossplot==0.5.5"]},{"cell_type":"code","source":["!cp /mnt/MyDrive/modeling_llama.py /usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py"],"metadata":{"id":"LoLC3Ke03A_x"},"id":"LoLC3Ke03A_x","execution_count":null,"outputs":[]},{"cell_type":"markdown","id":"2ebc37b1","metadata":{"id":"2ebc37b1"},"source":["Modify file for lora: `/usr/local/lib/python3.10/dist-packages/transformers/models/llama/modeling_llama.py`\n","\n","https://github.com/microsoft/LoRA#quickstart\n","```\n","# ===== Before =====\n","# layer = nn.Linear(in_features, out_features)\n","\n","# ===== After ======\n","import loralib as lora\n","# Add a pair of low-rank adaptation matrices with rank r=16\n","layer = lora.Linear(in_features, out_features, r=16)\n","```"]},{"cell_type":"code","execution_count":null,"id":"ab7fa8db","metadata":{"id":"ab7fa8db"},"outputs":[],"source":["import os\n","from os.path import join, dirname\n","import random\n","import warnings\n","\n","import numpy as np\n","import pandas as pd\n","\n","import torch\n","from torch import nn\n","\n","import loralib as lora\n","\n","import matplotlib.pyplot as plt\n","import seaborn as sns\n","\n","plt.style.use('ggplot')\n","warnings.filterwarnings('ignore')"]},{"cell_type":"markdown","id":"b8010cca","metadata":{"id":"b8010cca"},"source":["## 1.2 Random Seed"]},{"cell_type":"code","execution_count":null,"id":"8597cb46","metadata":{"id":"8597cb46"},"outputs":[],"source":["def seed_everything(seed: int=42):\n","    random.seed(seed)\n","    np.random.seed(seed)\n","    os.environ[\"PYTHONHASHSEED\"] = str(seed)\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed(seed)  # type: ignore\n","    torch.backends.cudnn.deterministic = True  # type: ignore\n","    torch.backends.cudnn.benchmark = True  # type: ignore\n","\n","seed_everything()"]},{"cell_type":"markdown","id":"557adedb","metadata":{"id":"557adedb"},"source":["## 1.3 PATH"]},{"cell_type":"code","execution_count":null,"id":"10ec6673","metadata":{"id":"10ec6673"},"outputs":[],"source":["class PATH:\n","    root   = '/root/court-decision-prediction'\n","    yaml   = join(root, 'court_decision_prediction/configs.yaml')\n","    data   = join(root, 'data/open')\n","    train  = join(data, 'train.csv')\n","    test   = join(data, 'test.csv')\n","    sample = join(data, 'sample_submission.csv')\n","    submit = join(root, 'submission')"]},{"cell_type":"markdown","id":"a864d2a0","metadata":{"id":"a864d2a0"},"source":["# 2. Load Dataset"]},{"cell_type":"markdown","id":"0b8dce3d","metadata":{"id":"0b8dce3d"},"source":["## 2.1 Load Raw Data"]},{"cell_type":"code","execution_count":null,"id":"4bea116c","metadata":{"id":"4bea116c"},"outputs":[],"source":["train_full_data = pd.read_csv(PATH.train)\n","test_data       = pd.read_csv(PATH.test)\n","target          = 'first_party_winner'"]},{"cell_type":"markdown","id":"9a9dbcae","metadata":{"id":"9a9dbcae"},"source":["## 2.2 Preprocessing\n","1. Group party into `united states`, `states`, `group1`, `group2`, `indiv`\n","2. Handle data imbalance\n","    - Stratified undersampling(`first_party_grp`)"]},{"cell_type":"code","execution_count":null,"id":"0bd0f630","metadata":{"id":"0bd0f630"},"outputs":[],"source":["from sklearn.preprocessing import LabelEncoder\n","from sklearn.utils import resample\n","\n","\n","def preprocess(data, target):\n","    data = append_party_group(data)\n","    if target in data:\n","        data = undersampling(data, target)\n","    return data\n","\n","\n","def append_party_group(data):\n","    data = data.copy()\n","    states = list(map(str.lower,\n","                      ['Alabama', 'Alaska', 'Arizona', 'Arkansas', 'California', 'Colorado', 'Connecticut', 'Delaware',\n","                       'Florida', 'Georgia', 'Hawaii', 'Idaho', 'Illinois', 'Indiana', 'Iowa', 'Kansas', 'Kentucky',\n","                       'Louisiana', 'Maine', 'Maryland', 'Massachusetts', 'Michigan', 'Minnesota', 'Mississippi',\n","                       'Missouri', 'Montana', 'Nebraska', 'Nevada', 'New Hampshire', 'New Jersey', 'New Mexico',\n","                       'New York', 'North Carolina', 'North Dakota', 'Ohio', 'Oklahoma', 'Oregon', 'Pennsylvania',\n","                       'Rhode Island', 'South Carolina', 'South Dakota', 'Tennessee', 'Texas', 'Utah', 'Vermont',\n","                       'Virginia', 'Washington', 'West Virginia', 'Wisconsin', 'Wyoming']))\n","    cities = ['new york', 'los angeles', 'chicago', 'houston', 'phoenix', 'philadelphia', 'san antonio', 'san diego',\n","              'dallas', 'san francisco', 'oakland', 'austin', 'jacksonville', 'san jose', 'california', 'indianapolis',\n","              'seattle', 'denver', 'washington', 'boston', 'el paso', 'nashville', 'detroit', 'oklahoma', 'portland',\n","              'las vegas', 'memphis', 'louisville', 'baltimore', 'milwaukee', 'albuquerque', 'tucson', 'fresno', 'mesa',\n","              'sacramento', 'atlanta', 'kansas city', 'colorado springs', 'omaha', 'raleigh', 'miami', 'long beach',\n","              'virginia beach', 'oakland', 'minneapolis', 'tulsa', 'tampa', 'arlington', 'new orleans', 'wichita',\n","              'cleveland', 'bakersfield', 'aurora', 'anaheim', 'honolulu', 'santa ana', 'riverside', 'corpus christi',\n","              'lexington', 'stockton', 'anchorage', 'st. paul', 'newark', 'buffalo', 'plano', 'henderson', 'fort wayne',\n","              'greensboro', 'lincoln', 'glendale', 'chandler', 'st. petersburg', 'jersey city', 'scottsdale', 'norfolk',\n","              'madison', 'orlando', 'birmingham', 'baton rouge', 'durham', 'laredo', 'garland', 'chula vista',\n","              'riverside', 'hialeah', 'lubbock', 'reno', 'north las vegas', 'akron', 'gilbert', 'rochester', 'boise',\n","              'spokane']\n","    def generate_fn(col):\n","        def fn(row):\n","            party = row[col].lower()\n","\n","            keywords1 = ['united states', 'federal', 'commision', 'commodity', 'national']\n","            keywords2 = states + cities + ['school board', 'city', 'republic', 'region', 'district', 'county']\n","            keywords3 = ['corporation', 'inc', 'company', 'bank', 'association', 'llc', 'co.', 'hospital', 'usa', 'school', 'group', 'office', 'department']\n","            keywords4 = [',', 'et al']\n","\n","            for grp, keywords in zip(['united states', 'states', 'group1', 'group2'],\n","                                    [keywords1, keywords2, keywords3, keywords4]):\n","                for key in keywords:\n","                    if key in party:\n","                        return grp\n","            return 'indiv'\n","        return fn\n","\n","    data['first_party_grp']  = data.apply(generate_fn('first_party'), axis=1)\n","    data['second_party_grp'] = data.apply(generate_fn('second_party'), axis=1)\n","    return data\n","\n","def undersampling(data, target):\n","    data_zero_target = data[data[target] == 0]\n","    data_one_target  = data[data[target] == 1]\n","    first_party_grp_int = LabelEncoder().fit_transform(data_one_target['first_party_grp'])\n","    data_one_target_sample = resample(data_one_target, replace=False, n_samples=len(data_zero_target), stratify=first_party_grp_int)\n","    return pd.concat([data_zero_target, data_one_target_sample], ignore_index=True)"]},{"cell_type":"code","execution_count":null,"id":"777b07bb","metadata":{"id":"777b07bb"},"outputs":[],"source":["train_full_data_pp = preprocess(train_full_data, target)\n","test_data_pp       = preprocess(test_data, target)"]},{"cell_type":"code","execution_count":null,"id":"b6dd6c1b","metadata":{"id":"b6dd6c1b"},"outputs":[],"source":["def plot_party(ax1, ax2, f):\n","    train_full_data_pp[f].value_counts().head(10).plot.bar(ax=ax1),        ax1.set_title(f\"{f} (# unique: {train_full_data_pp[f].nunique()})\")\n","    train_full_data_pp[f'{f}_grp'].value_counts().plot.bar(ax=ax2, rot=0), ax2.set_title(f\"{f}_grp (# unique: {train_full_data_pp[f+'_grp'].nunique()})\")\n","\n","for f in ('first_party', 'second_party'):\n","    fig, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 3))\n","    plot_party(ax1, ax2, f)"]},{"cell_type":"code","execution_count":null,"id":"8ee92600","metadata":{"id":"8ee92600"},"outputs":[],"source":["_, (ax1, ax2) = plt.subplots(ncols=2, figsize=(12, 3))\n","train_full_data[target].plot.hist(ax=ax1),    ax1.set_title(f\"{target} (before undersampling)\")\n","train_full_data_pp[target].plot.hist(ax=ax2), ax2.set_title(f\"{target} (after undersampling)\");"]},{"cell_type":"markdown","id":"cd6012e1","metadata":{"id":"cd6012e1"},"source":["## 2.3 Split Dataset"]},{"cell_type":"code","execution_count":null,"id":"b79fecec","metadata":{"id":"b79fecec"},"outputs":[],"source":["from sklearn.model_selection import train_test_split\n","\n","train_data, val_data = train_test_split(train_full_data_pp, test_size=0.3, stratify=train_full_data_pp[target])\n","len(train_data), len(val_data)"]},{"cell_type":"markdown","id":"7e51f871","metadata":{"id":"7e51f871"},"source":["# 3. Modeling"]},{"cell_type":"code","execution_count":null,"id":"3362627a","metadata":{"collapsed":true,"id":"3362627a"},"outputs":[],"source":["from transformers import LlamaForCausalLM, LlamaTokenizer\n","\n","model_id  = \"lmsys/vicuna-7b-v1.3\"\n","# model_id  = \"openlm-research/open_llama_3b\"\n","# model_id  = \"lmsys/fastchat-t5-3b-v1.0\"\n","\n","model     = LlamaForCausalLM.from_pretrained(model_id).to(torch.bfloat16)\n","tokenizer = LlamaTokenizer.from_pretrained(model_id)"]},{"cell_type":"markdown","id":"3c243291","metadata":{"id":"3c243291"},"source":["## 3.1 Test Model"]},{"cell_type":"code","execution_count":null,"id":"aa6b3f35","metadata":{"id":"aa6b3f35"},"outputs":[],"source":["# prompt = f\"\"\"Question: What is 1+1?\n","# Answer: \"\"\"\n","# input_ids = tokenizer(prompt, return_tensors=\"pt\").input_ids.to(model.device)\n","# with torch.no_grad():\n","#     outputs = model.generate(input_ids=input_ids, max_new_tokens=8)\n","# response = tokenizer.decode(outputs[0], skip_special_tokens=True)\n","# print(response)"]},{"cell_type":"markdown","id":"dd4ad152","metadata":{"id":"dd4ad152"},"source":["## 3.2 Test Tokenizer"]},{"cell_type":"code","execution_count":null,"id":"5a374b94","metadata":{"id":"5a374b94"},"outputs":[],"source":["# print(\"O:\", tokenizer.decode([438, 29949]))   # 29949: _O\n","# print(\"X:\", tokenizer.decode([1060, 29990]))  # 29990: _X\n","# print(\"Start token:\", tokenizer.decode([1]))"]},{"cell_type":"markdown","source":["## 3.3 Modify Model"],"metadata":{"id":"Ny74OwqU6wdq"},"id":"Ny74OwqU6wdq"},{"cell_type":"code","execution_count":null,"id":"12ce449c","metadata":{"id":"12ce449c"},"outputs":[],"source":["# Lora setting\n","model.requires_grad = False\n","lora.mark_only_lora_as_trainable(model)\n","\n","# Change trainable head\n","# model.lm_head = nn.Linear(3200, 1)  # 4096: hidden size, 1: binary classification (w.o. sigmoid)\n","model.lm_head = nn.Linear(4096, 1)  # 4096: hidden size, 1: binary classification (w.o. sigmoid)\n","model.lm_head.requires_grad = True\n","model = model.to(torch.bfloat16).cuda()"]},{"cell_type":"code","execution_count":null,"id":"40f88767","metadata":{"id":"40f88767"},"outputs":[],"source":["model"]},{"cell_type":"markdown","source":["# 4. Train"],"metadata":{"id":"42hth0yV7uzB"},"id":"42hth0yV7uzB"},{"cell_type":"code","source":["from torch.utils.data import Dataset, DataLoader\n","\n","\n","def get_prompt(first_party, second_party, facts):\n","    return f\"\"\"A chat between a curious user and an artificial intelligence assistant.\n","The assistant gives helpful and concise answers to the user's questions.\n","\n","USER:\n","- first_party: {first_party}\n","- second_party: {second_party}\n","- facts:\n","{facts[:1000]}\n","\n","- Question: I want to know whether the first_party can win the case. Tell me just the answer with O or X, without any detailed reasons.\n","\n","ASSISTANT:\n","- Answer: \"\"\"\n","\n","# def get_prompt(first_party, second_party, facts):\n","#     return f\"\"\"\n","# USER:\n","# - first_party: {first_party}\n","# - second_party: {second_party}\n","# - facts:\n","# {facts[:1000]}\n","# - Question: I want to know whether the first_party can win the case. Tell me just the answer with O or X, without any detailed reasons.\n","\n","# ASSISTANT:\n","# - Answer: \"\"\"\n","\n","\n","# def decode(output):\n","#     return tokenizer.decode(output[0], skip_special_tokens=True)\n","\n","class CustomDataset(Dataset):\n","    def __init__(self, data, target, tokenizer):\n","        self.data      = data\n","        self.target    = target\n","\n","        tokenizer.pad_token = tokenizer.eos_token  # use default pad token\n","        self.input_ids = self._get_input_ids(data, tokenizer)\n","        self.labels    = self._get_labels(data)\n","\n","    def _get_input_ids(self, data, tokenzier):\n","        prompts = []\n","        for idx_row in range(len(data)):\n","            row = self.data.iloc[idx_row]\n","            prompt = get_prompt(row['first_party'], row['second_party'], row['facts'])\n","            prompts.append(prompt)\n","        return tokenizer(prompts, return_tensors='pt', padding='longest').input_ids.cuda()\n","\n","    def _get_labels(self, data):\n","        if self.target in data:\n","            return len(data)*[None]\n","\n","        labels = []\n","        for idx_row in range(len(data)):\n","            row = data.iloc[idx_row]\n","            label = row[self.target]\n","            labels.append(label)\n","        return torch.tensor(labels, dtype=torch.bfloat16).cuda()\n","\n","    def __len__(self):\n","        return len(self.data)\n","\n","    def __getitem__(self, idx):\n","        input = self.input_ids[idx]\n","        label = self.labels[idx]\n","        return input, label\n","\n","\n","train_ds = CustomDataset(train_data, target, tokenizer)\n","val_ds   = CustomDataset(val_data, target, tokenizer)\n","\n","train_dl = DataLoader(train_ds, batch_size=1, shuffle=True)\n","val_dl   = DataLoader(val_ds,   batch_size=1, shuffle=False)"],"metadata":{"id":"Q4jtfxPk9aZT"},"id":"Q4jtfxPk9aZT","execution_count":null,"outputs":[]},{"cell_type":"code","execution_count":null,"id":"c0783f7b","metadata":{"id":"c0783f7b"},"outputs":[],"source":["from livelossplot import PlotLosses\n","from tqdm import trange, tqdm\n","\n","\n","def compute_loss_acc(X, y):\n","    output = model(X)\n","    logit  = output[0][0, -1]  # output of last sequence\n","    loss   = loss_fn(logit, y)\n","    acc    = (logit > 0) == y\n","    return loss, acc\n","\n","def train_step(X, y):\n","    loss, acc = compute_loss_acc(X, y)\n","    optimizer.zero_grad()\n","    loss.backward()\n","    optimizer.step()\n","    return loss.item(), acc.item()\n","\n","def val_step(X, y):\n","    loss, acc = compute_loss_acc(X, y)\n","    return loss.item(), acc.item()\n","\n","\n","loss_fn   = nn.BCEWithLogitsLoss().cuda()\n","optimizer = torch.optim.Adam(model.parameters())\n","\n","liveloss = PlotLosses()\n","history  = pd.DataFrame(columns=['loss', 'acc', 'val_loss', 'val_acc'], index=pd.Index([], name='Epoch'))\n","n_epochs = 10\n","for epoch in trange(1, n_epochs+1):\n","    avg_loss, avg_acc = [], []\n","    avg_val_loss, avg_val_acc = [], []\n","\n","    for X, y in tqdm(train_dl):\n","        loss, acc = train_step(X, y)\n","        avg_loss.append(loss), avg_acc.append(acc)\n","\n","    with torch.no_grad():\n","        for X, y in tqdm(val_dl):\n","            val_loss, val_acc = val_step(X, y)\n","            avg_val_loss.append(val_loss), avg_val_acc.append(val_acc)\n","\n","    history.loc[epoch] = np.mean([avg_loss, avg_acc, avg_val_loss, avg_val_acc], axis=1)\n","    liveloss.update(history.loc[epoch])\n","    liveloss.send()"]}],"metadata":{"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.12"},"colab":{"provenance":[],"machine_shape":"hm","gpuType":"T4"},"accelerator":"GPU"},"nbformat":4,"nbformat_minor":5}